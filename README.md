## ğŸ“˜ **README.md**


# ğŸ¤–AGI Assistant: Voice-Controlled Intelligent Desktop Automation System

## ğŸ§© Overview
**AGI Assistant** is an intelligent desktop automation tool that:
- Listens to your **voice commands**
- Records both **audio** and **screen activity**
- Performs **context-aware automation** such as opening Excel, File Explorer, Browser, or WhatsApp
- Generates a detailed **session summary (JSON)** describing the detected actions and extracted screen text

This project combines **speech recognition**, **OCR**, and **desktop automation** into one integrated workflow.

---

## âš™ï¸ Features
âœ… Voice-based automation using the **Vosk offline speech model**  
âœ… Screen OCR analysis with **Tesseract**  
âœ… Automatic generation of session logs in `/data/`  
âœ… Action detection â€” â€œopen excelâ€, â€œopen browserâ€, â€œopen whatsappâ€  
âœ… Fallback automation when no valid audio detected  
âœ… Cross-compatible â€” works both as `.py` and `.exe`

---

## ğŸ§  Project Workflow
1. Launches mic popup and records audio for a fixed duration (default: 10s)
2. Captures a screen video in parallel
3. Transcribes the audio â†’ detects intent (Excel, File Explorer, Browser, etc.)
4. Performs the matching action automatically
5. Extracts text from captured frames using Tesseract OCR
6. Saves results inside a new `data/session_YYYYMMDD_HHMMSS/` folder

---

## ğŸ§© Project Structure


AGI_Assistant1/

â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                # Main entry point

â”‚   â”œâ”€â”€ summarizer.py          # Speech + OCR summarization

â”‚   â”œâ”€â”€ automation_manager.py  # Executes detected automation

â”‚   â”œâ”€â”€ storage_manager.py     # Handles data/session management

â”‚   â”œâ”€â”€ recorder.py            # Audio & screen recording

â”‚   â””â”€â”€ ...

â”‚

â”œâ”€â”€ models/

â”‚   â””â”€â”€ vosk_model/            # Vosk speech recognition model files

â”‚
â”œâ”€â”€ config/

â”‚   â””â”€â”€ .env                   # Optional configuration (paths, duration, etc.)

â”‚

â”œâ”€â”€ data/                      # Saved session recordings and summaries

â”‚   â””â”€â”€ session_YYYYMMDD_HHMMSS/
â”‚

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ README.md

â””â”€â”€ AGI_Assistant.exe          # (Optional) Built executable



---

## ğŸª„ Installation

### 1ï¸âƒ£ Clone or extract the project
```bash
cd C:\Users\<YourName>\PycharmProjects\AGI_Assistant1
````

### 2ï¸âƒ£ Create and activate virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Place Vosk Model

Download a lightweight English model from:
ğŸ”— [https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)

Extract it inside:

```
models\vosk_model\
```

### 5ï¸âƒ£ Install Tesseract OCR

Install from:
ğŸ”— [https://github.com/UB-Mannheim/tesseract/wiki](https://github.com/UB-Mannheim/tesseract/wiki)

Then ensure the path is correct in `main.py` or `.env`:

```
TESSERACT_PATH=C:\Program Files\Tesseract-OCR\tesseract.exe
```

---

## â–¶ï¸ Usage

### ğŸ§© Run via Python

```bash
venv\Scripts\activate
python src\main.py
```

### ğŸ§© Run as Executable

After packaging with PyInstaller (see below), run:

```bash
cd dist
AGI_Assistant.exe
```

The mic symbol will appear briefly, then the app will:

* Record voice and screen
* Detect commands like:

  * â€œopen excelâ€
  * â€œopen browserâ€
  * â€œopen whatsappâ€
  * â€œopen filesâ€ (fallback)

Results will appear in `/data/session_.../summary.json`.

---

## ğŸ—ï¸ Building Executable (.exe)

### Run this in **CMD** (not PowerShell)

```cmd
cd C:\Users\<YourName>\PycharmProjects\AGI_Assistant1
venv\Scripts\activate
python -m PyInstaller --onefile --noconsole ^
--name "AGI_Assistant" ^
--add-data "models;models" ^
--add-data "config;config" ^
--add-data "data;data" ^
src\main.py
```

The output `.exe` will be located in:

```
dist\AGI_Assistant.exe
```

---

## ğŸ§¾ Output Example

**summary.json**

```json
{
    "timestamp": "20251028_121755",
    "audio_text": "open excel",
    "screen_text_samples": ["Microsoft Excel - Book1"],
    "detected_actions": [
        {"action": "Opened Excel", "source": "audio"},
        {"action": "Interacted with screen", "source": "ocr"}
    ],
    "final_action": "Opened Excel"
}
```

---

## ğŸ§¹ Logs & Cleanup

Old sessions are automatically cleaned when more than 10 exist (configurable in `.env`):

```
MAX_SESSIONS=10
```

---

## ğŸ§© Troubleshooting

| Issue                       | Fix                                                                 |
| --------------------------- | ------------------------------------------------------------------- |
| âŒ â€œexplorer not recognizedâ€ | Add `C:\Windows\explorer.exe` to PATH or use `os.startfile("C:\\")` |
| ğŸ™ï¸ Mic not recording       | Ensure audio permissions or update `pyaudio`                        |
| ğŸ§  No speech detected       | Check if vosk model folder exists                                   |
| âš™ï¸ OCR not extracting text  | Confirm `TESSERACT_PATH` is valid                                   |
| ğŸ’¥ .exe doesnâ€™t run         | Always rebuild after activating venv                                |

---

## ğŸ‘¨â€ğŸ’» Author

**Devasish Pothumudi**
AI/ML Engineer | Automation & Speech Systems Developer

---

## ğŸ“œ License

MIT License Â© 2025 Devasish Pothumudi

---
